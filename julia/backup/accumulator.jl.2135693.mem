        - using MPI
        - using Test
        - using EllipsisNotation
        - using HDF5
        - 
        - struct Accumulator
        -     count::Dict{String,UInt64}
        -     data::Dict{String,Any}
        -     num_temps::Integer
        -     function Accumulator(num_temps::Integer)
        -         new(Dict{String,UInt64}(), Dict{String,Any}(), num_temps)
        -     end
        - end
        - 
        - function add!(acc::Accumulator, name::String, data)
        0     @assert length(data) == acc.num_temps
        0     if !haskey(acc.count, name)
        0         acc.count[name] = 1
     1856         acc.data[name] = copy(data)
        -     else
        0         acc.count[name] += 1
        0         acc.data[name] += data
        -     end
        - end
        - 
        - function mean(acc::Accumulator, name::String)
        0     return acc.data[name]/acc.count[name]
        - end
        - 
        - function mean_gather(acc::Accumulator, name::String, comm)
        -     if typeof(acc.data[name]) <: Array
        -         return mean_gather_array(acc, name, comm)
        -     else
        -         return mean_gather_scalar(acc, name, comm)
        -     end
        - end
        - 
        - function mean_gather_scalar(acc::Accumulator, name::String, comm)
        0     counts = convert(Array{Cint}, MPI.Allgather(acc.num_temps, comm))
        0     results_local = mean(acc, name)
        0     return MPI.Gatherv(results_local, counts, 0, comm)
        - end
        - 
        - function mean_gather_array(acc::Accumulator, name::String, comm)
        0     rank = MPI.Comm_rank(comm)
        0     num_proc = MPI.Comm_size(comm)
        - 
        0     results_local = mean(acc, name)
        0     num_temps_local = length(results_local)
        0     num_temps = MPI.Allreduce(num_temps_local, MPI.SUM, comm)
      768     data_size = size(results_local[1])
      624     data_type = typeof(results_local[1])
        - 
     1872     for r in results_local
    23056         @test size(r) == data_size
    23040         @test typeof(r) == data_type
        -     end
        - 
        -     # Flatten data
      768     data_local_flatten = collect(Iterators.flatten(results_local))
        - 
        0     counts = convert(Array{Cint}, MPI.Allgather(length(data_local_flatten), comm))
        0     data_flatten = MPI.Gatherv(data_local_flatten, counts, 0, comm)
        0     if rank > 0
        0         return
        -     end
        - 
      768     right_dim = (num_temps,)
      912     data = reshape(data_flatten,  (data_size..., right_dim...))
        - 
    17664     result = Array{data_type}(undef, num_temps)
     3072     for it in 1:num_temps
      624         result[it] = data[.., it]
        -     end
        0     return result
        - end
        - 
        - function to_array(xs::Vector{Array{T,N}}) where {T, N}
        0     size_elem = size(xs[1])
      288     cat((reshape(x, (size_elem...,1)) for x in xs)..., dims=ndims(xs[1])+1)
        - end
        - 
        - function to_array(x::Vector{T}) where {T <: Number}
        0     return x
        - end
        - 
        - function save_to_hdf5!(acc, h5file, comm)
        0     rank = MPI.Comm_rank(comm)
        0     for name in keys(acc.data)
        0         mean_data = mean_gather(acc, name, comm)
        0         if rank == 0
        0             g = create_group(h5file, name)
        -             #g = g_create(h5file, name)
        -             #println("Writing $(name)...")
        0             g["mean"] = to_array(mean_data)
        -         end
        -     end
        - end
